# Imports:
import os.path
import argparse

from rl.callbacks import (
    FileLogger,
    ModelIntervalCheckpoint,
)

from minecraft_deep_learning.environment import build_environment
from minecraft_deep_learning.model import build_agent
from minecraft_deep_learning.processor import MinecraftProcessor
from minecraft_deep_learning.display import (
    close_display,
    get_pressed_action,
)
from minecraft_deep_learning.constants import (
    NUM_STEPS,
    LOG_INTERVAL,
    DEBUG_LOG_INTERVAL,
    TESTING_EPISODES,
    WEIGHTS_DIR,
    ESTIMATED_TIME,
    RANDOM_START_STEPS,
)

# Argument parser:
final_weights_file = os.path.join(WEIGHTS_DIR, "weights_final.h5f")

arguments = argparse.ArgumentParser()
arguments.add_argument(
    "--mode",
    choices=["train", "test", "play"],
    default="train",
)
arguments.add_argument(
    "--weights",
    type=str,
    default=final_weights_file,
)

# Argument handling:
def run_agent(env, args):
    """Follow the given parsed arguments in the given environment."""
    if args.mode == "play":
        proc = MinecraftProcessor()
        proc.use_display()
        proc._action = env.action_space.sample()
        def proc.handle_events():
            action_name = None
            while action_name is None:
                action_name = get_pressed_action()
            proc._action = env.action_names[0].index(action_name)
        done = True
        while True:
            if done:
                env.reset()
            obs, reward, done, info = (
                proc._action
                |> env.step
                |*> proc.process_step
            )
            print("received reward: {}".format(reward))

    elif args.mode == "train":
        agent = build_agent()
        print("Estimated training time: {}".format(ESTIMATED_TIME))
        callbacks = [
            ModelIntervalCheckpoint(
                os.path.join(WEIGHTS_DIR, "weights_{step}.h5f"),
                interval=LOG_INTERVAL,
            ),
            FileLogger(
                os.path.join(WEIGHTS_DIR, "log.json"),
                interval=DEBUG_LOG_INTERVAL,
            ),
        ]
        agent.fit(
            env,
            callbacks=callbacks,
            nb_steps=NUM_STEPS,
            nb_max_start_steps=RANDOM_START_STEPS,
            log_interval=LOG_INTERVAL,
        )
        agent.save_weights(final_weights_file, overwrite=True)

    elif args.mode == "test":
        agent = build_agent()
        agent.load_weights(args.weights)
        agent.test(
            env,
            nb_episodes=TESTING_EPISODES,
            nb_max_start_steps=RANDOM_START_STEPS,
            visualize=False,
        )

    else:
        raise ValueError("unknown --mode {!r}".format(args.mode))

def main(raw_args=None):
    """Parse arguments, build environment, and run agent."""
    if raw_args is None:
        args = arguments.parse_args()
    else:
        args = arguments.parse_args(raw_args)
    env = build_environment()
    try:
        run_agent(env, args)
    finally:
        close_display()
        env.close()
