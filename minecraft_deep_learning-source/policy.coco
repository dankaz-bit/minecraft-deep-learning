# Imports:
import numpy as np
from rl.policy import BoltzmannQPolicy

from minecraft_deep_learning.constants import (
    LOG_INTERVAL,
    DEBUG,
    BOLTZMANN_TAU,
    USE_ACTIONS,
)

# Policy setup:
def build_policies():
    """Build the training and test exploration policies."""
    print("Using Boltzmann exploration with tau = {}".format(BOLTZMANN_TAU))
    policy = BoltzmannQPolicy(tau=BOLTZMANN_TAU)

    if DEBUG:
        policy._counter = 0
        policy._greedy_counter = 0
        old_select_action = policy.select_action
        def policy.select_action(q_values):
            if policy._counter and policy._counter % LOG_INTERVAL == 0:
                print("\neffective epsilon: {} (non-greedy {}/{} times)".format(
                    (1 - policy._greedy_counter/policy._counter)/(len(USE_ACTIONS) - 1),
                    policy._counter - policy._greedy_counter,
                    policy._counter,
                ))
            best_action = np.argmax(q_values)
            action = old_select_action(q_values)
            if action == best_action:
                policy._greedy_counter += 1
            policy._counter += 1
            return action

    return policy, policy  # train and test policies are identical
